2018-12-08 20:43:33.313861: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
initializing system parameters
--------------Starting training  predictions_1d_conv_activ_exp0.001
Fold:  0
##################################################
Epoch 1/50
Using TensorFlow backend.
main.py:148: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  train["actual_label_idx"] = train.label.apply(lambda x: label_idx[x])

1/3 [=========>....................] - ETA: 9s - loss: nan - acc: 0.5781
2/3 [===================>..........] - ETA: 2s - loss: nan - acc: 0.5340
3/3 [==============================] - 9s 3s/step - loss: nan - acc: 0.5127 - val_loss: nan - val_acc: 0.5141

Epoch 00001: val_loss did not improve from inf
Epoch 2/50

1/3 [=========>....................] - ETA: 5s - loss: nan - acc: 0.5781
2/3 [===================>..........] - ETA: 1s - loss: nan - acc: 0.5340
3/3 [==============================] - 7s 2s/step - loss: nan - acc: 0.5127 - val_loss: nan - val_acc: 0.5141

Epoch 00002: val_loss did not improve from inf
Epoch 3/50

1/3 [=========>....................] - ETA: 4s - loss: nan - acc: 0.4898
2/3 [===================>..........] - ETA: 1s - loss: nan - acc: 0.4793
3/3 [==============================] - 7s 2s/step - loss: nan - acc: 0.5127 - val_loss: nan - val_acc: 0.5141

Epoch 00003: val_loss did not improve from inf

1/3 [=========>....................] - ETA: 16s
2/3 [===================>..........] - ETA: 4s 
3/3 [==============================] - 10s 3s/step

1/2 [==============>...............] - ETA: 7s
2/2 [==============================] - 8s 4s/step
Fold:  1
##################################################
main.py:92: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  test['predicted_label'] = predicted_labels
Epoch 1/50

1/3 [=========>....................] - ETA: 10s - loss: nan - acc: 0.5156
2/3 [===================>..........] - ETA: 3s - loss: nan - acc: 0.5234 
3/3 [==============================] - 10s 3s/step - loss: nan - acc: 0.5127 - val_loss: nan - val_acc: 0.5141

Epoch 00001: val_loss did not improve from inf
Epoch 2/50

1/3 [=========>....................] - ETA: 6s - loss: nan - acc: 0.5156
2/3 [===================>..........] - ETA: 2s - loss: nan - acc: 0.5027
3/3 [==============================] - 8s 3s/step - loss: nan - acc: 0.5127 - val_loss: nan - val_acc: 0.5141

Epoch 00002: val_loss did not improve from inf
Epoch 3/50

1/3 [=========>....................] - ETA: 7s - loss: nan - acc: 0.5312
2/3 [===================>..........] - ETA: 2s - loss: nan - acc: 0.5105
3/3 [==============================] - 8s 3s/step - loss: nan - acc: 0.5127 - val_loss: nan - val_acc: 0.5141

Epoch 00003: val_loss did not improve from inf

1/3 [=========>....................] - ETA: 16s
2/3 [===================>..........] - ETA: 4s 
3/3 [==============================] - 10s 3s/step

1/2 [==============>...............] - ETA: 7s
2/2 [==============================] - 8s 4s/step
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################

--------------Starting training  predictions_1d_conv_double_deep_unif0.001
Fold:  0
##################################################
Epoch 1/50

1/3 [=========>....................] - ETA: 17s - loss: 0.6931 - acc: 0.3906
2/3 [===================>..........] - ETA: 6s - loss: 0.6934 - acc: 0.4297 
3/3 [==============================] - 22s 7s/step - loss: 0.6934 - acc: 0.4489 - val_loss: 0.6930 - val_acc: 0.5141

Epoch 00001: val_loss improved from inf to 0.69301, saving model to models/predictions_1d_conv_double_deep_unif0.001/best_0.h5
Epoch 2/50

1/3 [=========>....................] - ETA: 8s - loss: 0.6935 - acc: 0.4688
2/3 [===================>..........] - ETA: 4s - loss: 0.6933 - acc: 0.5234
3/3 [==============================] - 17s 6s/step - loss: 0.6933 - acc: 0.5127 - val_loss: 0.6930 - val_acc: 0.5141

Epoch 00002: val_loss improved from 0.69301 to 0.69298, saving model to models/predictions_1d_conv_double_deep_unif0.001/best_0.h5
Epoch 3/50

1/3 [=========>....................] - ETA: 8s - loss: 0.6936 - acc: 0.4688
2/3 [===================>..........] - ETA: 3s - loss: 0.6935 - acc: 0.4793
3/3 [==============================] - 18s 6s/step - loss: 0.6931 - acc: 0.5127 - val_loss: 0.6929 - val_acc: 0.5141

Epoch 00003: val_loss improved from 0.69298 to 0.69294, saving model to models/predictions_1d_conv_double_deep_unif0.001/best_0.h5
Epoch 4/50

1/3 [=========>....................] - ETA: 9s - loss: 0.6938 - acc: 0.4688
2/3 [===================>..........] - ETA: 4s - loss: 0.6928 - acc: 0.5234
3/3 [==============================] - 17s 6s/step - loss: 0.6930 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00004: val_loss improved from 0.69294 to 0.69282, saving model to models/predictions_1d_conv_double_deep_unif0.001/best_0.h5
Epoch 5/50

1/3 [=========>....................] - ETA: 9s - loss: 0.6906 - acc: 0.5781
2/3 [===================>..........] - ETA: 3s - loss: 0.6922 - acc: 0.5340
3/3 [==============================] - 17s 6s/step - loss: 0.6933 - acc: 0.5127 - val_loss: 0.6927 - val_acc: 0.5141

Epoch 00005: val_loss improved from 0.69282 to 0.69275, saving model to models/predictions_1d_conv_double_deep_unif0.001/best_0.h5
Epoch 6/50

1/3 [=========>....................] - ETA: 9s - loss: 0.6893 - acc: 0.5781
2/3 [===================>..........] - ETA: 4s - loss: 0.6924 - acc: 0.5234
3/3 [==============================] - 18s 6s/step - loss: 0.6931 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00006: val_loss did not improve from 0.69275
Epoch 7/50

1/3 [=========>....................] - ETA: 7s - loss: 0.6945 - acc: 0.4898
2/3 [===================>..........] - ETA: 4s - loss: 0.6950 - acc: 0.4793
3/3 [==============================] - 19s 6s/step - loss: 0.6932 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00007: val_loss did not improve from 0.69275
Epoch 8/50

1/3 [=========>....................] - ETA: 9s - loss: 0.6900 - acc: 0.5781
2/3 [===================>..........] - ETA: 4s - loss: 0.6925 - acc: 0.5234
3/3 [==============================] - 18s 6s/step - loss: 0.6930 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00008: val_loss did not improve from 0.69275

1/3 [=========>....................] - ETA: 20s
2/3 [===================>..........] - ETA: 6s 
3/3 [==============================] - 17s 6s/step

1/2 [==============>...............] - ETA: 9s
2/2 [==============================] - 10s 5s/step
Fold:  1
##################################################
main.py:92: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  test['predicted_label'] = predicted_labels
Epoch 1/50

1/3 [=========>....................] - ETA: 14s - loss: 0.6931 - acc: 0.5306
2/3 [===================>..........] - ETA: 5s - loss: 0.6932 - acc: 0.4997 
3/3 [==============================] - 23s 8s/step - loss: 0.6932 - acc: 0.5045 - val_loss: 0.6929 - val_acc: 0.5141

Epoch 00001: val_loss improved from inf to 0.69285, saving model to models/predictions_1d_conv_double_deep_unif0.001/best_1.h5
Epoch 2/50

1/3 [=========>....................] - ETA: 6s - loss: 0.6936 - acc: 0.4898
2/3 [===================>..........] - ETA: 3s - loss: 0.6929 - acc: 0.5105
3/3 [==============================] - 17s 6s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6927 - val_acc: 0.5141

Epoch 00002: val_loss improved from 0.69285 to 0.69275, saving model to models/predictions_1d_conv_double_deep_unif0.001/best_1.h5
Epoch 3/50

1/3 [=========>....................] - ETA: 7s - loss: 0.6940 - acc: 0.4898
2/3 [===================>..........] - ETA: 3s - loss: 0.6930 - acc: 0.5105
3/3 [==============================] - 18s 6s/step - loss: 0.6928 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00003: val_loss did not improve from 0.69275
Epoch 4/50

1/3 [=========>....................] - ETA: 9s - loss: 0.6919 - acc: 0.5312
2/3 [===================>..........] - ETA: 4s - loss: 0.6925 - acc: 0.5234
3/3 [==============================] - 18s 6s/step - loss: 0.6933 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00004: val_loss did not improve from 0.69275
Epoch 5/50

1/3 [=========>....................] - ETA: 9s - loss: 0.6917 - acc: 0.5312
2/3 [===================>..........] - ETA: 3s - loss: 0.6931 - acc: 0.5105
3/3 [==============================] - 18s 6s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00005: val_loss did not improve from 0.69275

1/3 [=========>....................] - ETA: 19s
2/3 [===================>..........] - ETA: 6s 
3/3 [==============================] - 15s 5s/step

1/2 [==============>...............] - ETA: 9s
2/2 [==============================] - 10s 5s/step
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################

--------------Starting training  predictions_1d_conv_double_deep_mixed0.001
Fold:  0
##################################################
Epoch 1/50

1/3 [=========>....................] - ETA: 46s - loss: 0.6931 - acc: 0.4531
2/3 [===================>..........] - ETA: 21s - loss: 0.6938 - acc: 0.4375
3/3 [==============================] - 77s 26s/step - loss: 0.6936 - acc: 0.4607 - val_loss: 0.6931 - val_acc: 0.5141

Epoch 00001: val_loss improved from inf to 0.69309, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 2/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6928 - acc: 0.5781
2/3 [===================>..........] - ETA: 18s - loss: 0.6932 - acc: 0.5234
3/3 [==============================] - 72s 24s/step - loss: 0.6932 - acc: 0.5127 - val_loss: 0.6929 - val_acc: 0.5141

Epoch 00002: val_loss improved from 0.69309 to 0.69294, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 3/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6918 - acc: 0.5781
2/3 [===================>..........] - ETA: 18s - loss: 0.6929 - acc: 0.5234
3/3 [==============================] - 74s 25s/step - loss: 0.6931 - acc: 0.5127 - val_loss: 0.6929 - val_acc: 0.5141

Epoch 00003: val_loss improved from 0.69294 to 0.69287, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 4/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6912 - acc: 0.5781
2/3 [===================>..........] - ETA: 18s - loss: 0.6927 - acc: 0.5234
3/3 [==============================] - 74s 25s/step - loss: 0.6930 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00004: val_loss improved from 0.69287 to 0.69282, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 5/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6908 - acc: 0.5781
2/3 [===================>..........] - ETA: 18s - loss: 0.6926 - acc: 0.5234
3/3 [==============================] - 72s 24s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00005: val_loss improved from 0.69282 to 0.69280, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 6/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6945 - acc: 0.4688
2/3 [===================>..........] - ETA: 16s - loss: 0.6941 - acc: 0.4793
3/3 [==============================] - 72s 24s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00006: val_loss did not improve from 0.69280
Epoch 7/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6905 - acc: 0.5781
2/3 [===================>..........] - ETA: 16s - loss: 0.6921 - acc: 0.5340
3/3 [==============================] - 73s 24s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00007: val_loss improved from 0.69280 to 0.69278, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 8/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6901 - acc: 0.5781
2/3 [===================>..........] - ETA: 16s - loss: 0.6920 - acc: 0.5340
3/3 [==============================] - 73s 24s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00008: val_loss improved from 0.69278 to 0.69276, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 9/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6898 - acc: 0.5781
2/3 [===================>..........] - ETA: 18s - loss: 0.6924 - acc: 0.5234
3/3 [==============================] - 72s 24s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00009: val_loss improved from 0.69276 to 0.69276, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 10/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6897 - acc: 0.5781
2/3 [===================>..........] - ETA: 16s - loss: 0.6918 - acc: 0.5340
3/3 [==============================] - 72s 24s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00010: val_loss improved from 0.69276 to 0.69275, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 11/50

1/3 [=========>....................] - ETA: 28s - loss: 0.6940 - acc: 0.4898
2/3 [===================>..........] - ETA: 16s - loss: 0.6945 - acc: 0.4793
3/3 [==============================] - 73s 24s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00011: val_loss did not improve from 0.69275
Epoch 12/50

1/3 [=========>....................] - ETA: 38s - loss: 0.6897 - acc: 0.5781
2/3 [===================>..........] - ETA: 18s - loss: 0.6924 - acc: 0.5234
3/3 [==============================] - 73s 24s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00012: val_loss did not improve from 0.69275
Epoch 13/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6896 - acc: 0.5781
2/3 [===================>..........] - ETA: 18s - loss: 0.6923 - acc: 0.5234
3/3 [==============================] - 72s 24s/step - loss: 0.6928 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00013: val_loss improved from 0.69275 to 0.69275, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 14/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6895 - acc: 0.5781
2/3 [===================>..........] - ETA: 16s - loss: 0.6918 - acc: 0.5340
3/3 [==============================] - 74s 25s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00014: val_loss improved from 0.69275 to 0.69275, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_0.h5
Epoch 15/50

1/3 [=========>....................] - ETA: 28s - loss: 0.6939 - acc: 0.4898
2/3 [===================>..........] - ETA: 16s - loss: 0.6945 - acc: 0.4793
3/3 [==============================] - 74s 25s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00015: val_loss did not improve from 0.69275
Epoch 16/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6950 - acc: 0.4688
2/3 [===================>..........] - ETA: 16s - loss: 0.6945 - acc: 0.4793
3/3 [==============================] - 73s 24s/step - loss: 0.6930 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00016: val_loss did not improve from 0.69275
Epoch 17/50

1/3 [=========>....................] - ETA: 29s - loss: 0.6938 - acc: 0.4898
2/3 [===================>..........] - ETA: 16s - loss: 0.6943 - acc: 0.4793
3/3 [==============================] - 73s 24s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00017: val_loss did not improve from 0.69275

1/3 [=========>....................] - ETA: 39s
2/3 [===================>..........] - ETA: 16s
3/3 [==============================] - 46s 15s/step

1/2 [==============>...............] - ETA: 20s
2/2 [==============================] - 23s 12s/step
Fold:  1
##################################################
main.py:92: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  test['predicted_label'] = predicted_labels
Epoch 1/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6931 - acc: 0.4490
2/3 [===================>..........] - ETA: 18s - loss: 0.6933 - acc: 0.4589Epoch 1/50

3/3 [==============================] - 78s 26s/step - loss: 0.6932 - acc: 0.4784 - val_loss: 0.6929 - val_acc: 0.5141

Epoch 00001: val_loss improved from inf to 0.69291, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_1.h5
Epoch 2/50

1/3 [=========>....................] - ETA: 28s - loss: 0.6934 - acc: 0.4898
2/3 [===================>..........] - ETA: 16s - loss: 0.6929 - acc: 0.5105
3/3 [==============================] - 74s 25s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00002: val_loss improved from 0.69291 to 0.69277, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_1.h5
Epoch 3/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6920 - acc: 0.5312
2/3 [===================>..........] - ETA: 18s - loss: 0.6924 - acc: 0.5234
3/3 [==============================] - 72s 24s/step - loss: 0.6930 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00003: val_loss improved from 0.69277 to 0.69277, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_1.h5
Epoch 4/50

1/3 [=========>....................] - ETA: 37s - loss: 0.6926 - acc: 0.5156
2/3 [===================>..........] - ETA: 18s - loss: 0.6921 - acc: 0.5234
3/3 [==============================] - 72s 24s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00004: val_loss did not improve from 0.69277
Epoch 5/50

1/3 [=========>....................] - ETA: 38s - loss: 0.6926 - acc: 0.5156
2/3 [===================>..........] - ETA: 16s - loss: 0.6936 - acc: 0.5027
3/3 [==============================] - 75s 25s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00005: val_loss improved from 0.69277 to 0.69276, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_1.h5
Epoch 6/50

1/3 [=========>....................] - ETA: 39s - loss: 0.6916 - acc: 0.5312
2/3 [===================>..........] - ETA: 19s - loss: 0.6921 - acc: 0.5234
3/3 [==============================] - 76s 25s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00006: val_loss improved from 0.69276 to 0.69275, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_1.h5
Epoch 7/50

1/3 [=========>....................] - ETA: 38s - loss: 0.6916 - acc: 0.5312
2/3 [===================>..........] - ETA: 16s - loss: 0.6929 - acc: 0.5105
3/3 [==============================] - 74s 25s/step - loss: 0.6928 - acc: 0.5127 - val_loss: 0.6927 - val_acc: 0.5141

Epoch 00007: val_loss improved from 0.69275 to 0.69275, saving model to models/predictions_1d_conv_double_deep_mixed0.001/best_1.h5
Epoch 8/50

1/3 [=========>....................] - ETA: 29s - loss: 0.6941 - acc: 0.4898
2/3 [===================>..........] - ETA: 16s - loss: 0.6934 - acc: 0.5027
3/3 [==============================] - 77s 26s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00008: val_loss did not improve from 0.69275
Epoch 9/50

1/3 [=========>....................] - ETA: 38s - loss: 0.6920 - acc: 0.5312
2/3 [===================>..........] - ETA: 19s - loss: 0.6923 - acc: 0.5234
3/3 [==============================] - 75s 25s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00009: val_loss did not improve from 0.69275
Epoch 10/50

1/3 [=========>....................] - ETA: 38s - loss: 0.6924 - acc: 0.5156
2/3 [===================>..........] - ETA: 19s - loss: 0.6921 - acc: 0.5234
3/3 [==============================] - 75s 25s/step - loss: 0.6929 - acc: 0.5127 - val_loss: 0.6928 - val_acc: 0.5141

Epoch 00010: val_loss did not improve from 0.69275

1/3 [=========>....................] - ETA: 42s
2/3 [===================>..........] - ETA: 17s
3/3 [==============================] - 48s 16s/step

1/2 [==============>...............] - ETA: 20s
2/2 [==============================] - 24s 12s/step
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################

